{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84bf70f4-915d-4738-b78c-700b27b06f38",
   "metadata": {
    "id": "84bf70f4-915d-4738-b78c-700b27b06f38"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/stefanlessmann/ESMT_IML/blob/main/notebooks/p3_classification.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2e2f2f-70e7-4662-9aa1-07b5bb50585d",
   "metadata": {
    "id": "ce46c39d-cfa8-4bca-82b2-c6364fd44819"
   },
   "source": [
    "# Practical 3: Probability of Default (PD) Prediction\n",
    "<hr>\n",
    "In this practice session, we revisit the logistic regression model and study how it allows us to approach classification problems in the scope of banking and finance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c084741-bb8f-48c2-afbe-5236af75860b",
   "metadata": {
    "executionInfo": {
     "elapsed": 2466,
     "status": "ok",
     "timestamp": 1695536714957,
     "user": {
      "displayName": "Ben Joshua Fliegener",
      "userId": "06969016385245233563"
     },
     "user_tz": -120
    },
    "id": "wIgF2_GabxOZ"
   },
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd477e7a-c3c4-4952-b50b-4cd3d866906c",
   "metadata": {},
   "source": [
    "## Binary classification for PD modeling\n",
    "In the first part of the exercise, we come back to the credit risk prediction data set used in our [first session](https://github.com/stefanlessmann/ESMT_IML/blob/main/notebooks/p1_AI_peer_programming.ipynb) and also the demo of an [entire ML pipeline](https://github.com/stefanlessmann/ESMT_IML/blob/main/notebooks/p0_demo_ml_pipeline.ipynb).  \n",
    "\n",
    "### Loading and preparing the data\n",
    "We retrieve the data from GitHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd776c45-c9d5-449e-91ba-f407dbeaaca9",
   "metadata": {
    "id": "28M_8V9LkG6Y",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5960 entries, 0 to 5959\n",
      "Data columns (total 13 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   BAD      5960 non-null   int64  \n",
      " 1   LOAN     5960 non-null   int64  \n",
      " 2   MORTDUE  5442 non-null   float64\n",
      " 3   VALUE    5848 non-null   float64\n",
      " 4   REASON   5708 non-null   object \n",
      " 5   JOB      5681 non-null   object \n",
      " 6   YOJ      5445 non-null   float64\n",
      " 7   DEROG    5252 non-null   float64\n",
      " 8   DELINQ   5380 non-null   float64\n",
      " 9   CLAGE    5652 non-null   float64\n",
      " 10  NINQ     5450 non-null   float64\n",
      " 11  CLNO     5738 non-null   float64\n",
      " 12  DEBTINC  4693 non-null   float64\n",
      "dtypes: float64(9), int64(2), object(2)\n",
      "memory usage: 605.4+ KB\n"
     ]
    }
   ],
   "source": [
    "data_location = 'https://raw.githubusercontent.com/stefanlessmann/ESMT_IML/master/data/hmeq.csv'\n",
    "df = pd.read_csv(data_location)  # standard pandas function to load tabular data in CSV format\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2f150d-6ecb-4005-8a87-39a84c71fcfd",
   "metadata": {},
   "source": [
    "Recall the meaning of the features:\n",
    "- BAD: the target variable, 1=default; 0=non-default\n",
    "- LOAN: amount of the loan request\n",
    "- MORTDUE: amount due on an existing mortgage\n",
    "- VALUE: value of current property\n",
    "- REASON: DebtCon=debt consolidation; HomeImp=home improvement\n",
    "- JOB: occupational categories\n",
    "- YOJ: years at present job\n",
    "- DEROG: number of major derogatory reports\n",
    "- DELINQ: number of delinquent credit lines\n",
    "- CLAGE: age of oldest credit line in months\n",
    "- NINQ: number of recent credit inquiries\n",
    "- CLNO: number of credit lines\n",
    "- DEBTINC: debt-to-income ratio\n",
    "\n",
    "Here is a snapshot of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "504665e7-8aeb-4ba1-a56e-28ba700880db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BAD</th>\n",
       "      <th>LOAN</th>\n",
       "      <th>MORTDUE</th>\n",
       "      <th>VALUE</th>\n",
       "      <th>REASON</th>\n",
       "      <th>JOB</th>\n",
       "      <th>YOJ</th>\n",
       "      <th>DEROG</th>\n",
       "      <th>DELINQ</th>\n",
       "      <th>CLAGE</th>\n",
       "      <th>NINQ</th>\n",
       "      <th>CLNO</th>\n",
       "      <th>DEBTINC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1100</td>\n",
       "      <td>25860.0</td>\n",
       "      <td>39025.0</td>\n",
       "      <td>HomeImp</td>\n",
       "      <td>Other</td>\n",
       "      <td>10.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>94.366667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1300</td>\n",
       "      <td>70053.0</td>\n",
       "      <td>68400.0</td>\n",
       "      <td>HomeImp</td>\n",
       "      <td>Other</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>121.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1500</td>\n",
       "      <td>13500.0</td>\n",
       "      <td>16700.0</td>\n",
       "      <td>HomeImp</td>\n",
       "      <td>Other</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>149.466667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1700</td>\n",
       "      <td>97800.0</td>\n",
       "      <td>112000.0</td>\n",
       "      <td>HomeImp</td>\n",
       "      <td>Office</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   BAD  LOAN  MORTDUE     VALUE   REASON     JOB   YOJ  DEROG  DELINQ  \\\n",
       "0    1  1100  25860.0   39025.0  HomeImp   Other  10.5    0.0     0.0   \n",
       "1    1  1300  70053.0   68400.0  HomeImp   Other   7.0    0.0     2.0   \n",
       "2    1  1500  13500.0   16700.0  HomeImp   Other   4.0    0.0     0.0   \n",
       "3    1  1500      NaN       NaN      NaN     NaN   NaN    NaN     NaN   \n",
       "4    0  1700  97800.0  112000.0  HomeImp  Office   3.0    0.0     0.0   \n",
       "\n",
       "        CLAGE  NINQ  CLNO  DEBTINC  \n",
       "0   94.366667   1.0   9.0      NaN  \n",
       "1  121.833333   0.0  14.0      NaN  \n",
       "2  149.466667   1.0  10.0      NaN  \n",
       "3         NaN   NaN   NaN      NaN  \n",
       "4   93.333333   0.0  14.0      NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde84bc6-bf07-42dc-8623-47791e846843",
   "metadata": {},
   "source": [
    "The data requires at least a little bit of preparation to be ready for machine learning. First, we need to address the missing values. Second, two of the features, REASON and JOB, are non-numeric. Such categorical features cannot be used in a logistic regression model. We must convert them to numbers before using them. The following code addresses both problems in a quick but also simplistic way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85fb7f37-fbcd-41a6-9814-23b9dce5c08d",
   "metadata": {
    "id": "28M_8V9LkG6Y",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convert a category with k different values into k-1 binary variables. \n",
    "X = pd.get_dummies(df, dummy_na=True, drop_first=True)\n",
    "X = X.dropna().reset_index(drop=True)  # drop all cases with one or more missing value\n",
    "\n",
    "# Separate the data into a matrix of feature values and a target variable\n",
    "y = X.pop('BAD')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d2ea9f-4363-42a7-a5a3-ec2d037cff01",
   "metadata": {},
   "source": [
    "### Excercise 1: Plotting data for classification\n",
    "You will remember the many plots we came across when discussing regression. We also saw some analog plots for classification problems in the lecture. One of them was a 2d scatter plot displaying the bi-variate relationship between selected features and the binary target variable. \n",
    "\n",
    "![Classification problem in 2D](https://raw.githubusercontent.com/stefanlessmann/ESMT_IML/main/resources/2d_classification_problem.png)\n",
    "\n",
    "Your first task is to create a similar plot for the credit data. In principle, you can select any combination of features that you like.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1056e886-fb90-4846-a961-fe6543a6ed6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1\n",
    "x1 = ''  # select first feature of your choice\n",
    "x2 = ''  # select second feature of your choice\n",
    "\n",
    "# Write code to create the scatter plot of x1 vs. x2. Make sure your plot shows the data points from different classes (good and bad payers) in different colors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87a590d-19b5-4966-bd5e-58840e0df1f7",
   "metadata": {},
   "source": [
    "For the sake of completeness, the lecture also introduced a different 2D plot, in which we chart the target variable against one of the features. Provided you have made a choice above, by assigning variable `x1` some valid feature name, you will be able to execute the below code to create this type of plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b409d9-6395-4ef5-b07d-642cf8ebebdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to depict how the values of one feature, x1, distribute across the values of the target variable\n",
    "\n",
    "# Just to make sure you did indeed a assign x1 a valid value ;)\n",
    "assert x1 != '', \"please assign a valid feature name to varible x2, like, e.g., x2='DEBTINC'\"\n",
    "\n",
    "# Plotting\n",
    "plt.scatter(X[x1], y, c=y)\n",
    "plt.xlabel(x1)\n",
    "plt.ylabel('BAD=1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5d64d5-d9a6-47fb-8c07-62d2d6d1f72e",
   "metadata": {},
   "source": [
    "Feel free to *play* with the above code and create the plot for several features. Note down some of your findings. The following questions can guide your thinking: \n",
    "- Will logistic regression work well with this data?\n",
    "- Which feature appears to be most indicate of whether a credit applicant defaults or not?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a1b465-84f4-41c7-ac34-340d012751ed",
   "metadata": {},
   "source": [
    "**Write down you answers**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8b7afe-1a24-4acc-8b1e-1b89a157134c",
   "metadata": {},
   "source": [
    "### Excercise 2: Model adequacy  \n",
    "We introduced logistic regression as an extension of linear regression for cases in which we work with a binary target variable. Nonetheless, just as linear regression, logistic regression is a linear model. It fits a line to the data.\n",
    "\n",
    "Play with the above code to plot the distribution of different combinations of the features. Eventually, you should arrive at a preliminary conclusion of whether logistic regression is a suitable model for the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d1dc3f-0098-443d-8801-2028441397e8",
   "metadata": {},
   "source": [
    "**Do you think logistic regression is suitable for the data? Briefly explain your reasoning.**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Also, has the analysis of different scatter plots revealed strong features that will facilitate predicting class membership (i.e., repayment behavior)?**\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e742e463-9ab9-49ca-a84e-3c1bfb004a90",
   "metadata": {},
   "source": [
    "## Logistic regression\n",
    "Time to estimate our first model. The below code uses the `sklearn` library to train a logistic regression classifier on the data. \n",
    "\n",
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2c9bfc1-ab50-465e-934f-1034f587ff0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(random_state=888)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(random_state=888).fit(X, y)  # we define a random_state to ensure that we get the same results when re-running this cell multiple times\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7eb9920-d1b3-4a19-9dfa-0a14bb7210bc",
   "metadata": {},
   "source": [
    "Note that the `sklearn` implementation does not provide an informative summary, as did the library `statsmodels` in our last practical. In brief, this is because `sklearn` is designed to support prediction. Let's demonstrate how to do this, that is compute predictions using the trained model. For simplicity, we compute prediction for the training data. Soon we will learn that this is actually inappropriate. Yet, we do it here to not overcomplicate things. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2856dfd-fe11-4ed1-803e-63f66c58b691",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model.predict(X)  # simply way to compute predictions using logistic regression and any other machine learning model in sklearn "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4565bc58-709f-4b00-919c-82ea24b30082",
   "metadata": {},
   "source": [
    "Likely, you are also interested to assess the model. There is an easy way to do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7039a29-fedc-4932-a098-8052bf57657a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logit model achieves a score of 91.209 %\n"
     ]
    }
   ],
   "source": [
    "perf = model.score(X, y)  # Call a general purpose evaluation function and obtain a (quality ) score of the model\n",
    "print('Logit model achieves a score of {:.3f} %'.format(perf*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b7202a-455b-44a3-9d16-78c40a5ea1a3",
   "metadata": {},
   "source": [
    "### Exercise 3: Diagnosing predictions\n",
    "A score of above 90 percent sounds very good. Actually, it is not, and your task is to find out why. Let's break it down into pieces.\n",
    "\n",
    "#### A) What score?\n",
    "Check the sklearn documentation to understand what kind of score the function `score()` has provided. What is it that we see?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03225801-d197-471b-a2be-c88aff8d126e",
   "metadata": {},
   "source": [
    "**Your answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786a24e3-05d9-4439-8958-f7459cd0af4f",
   "metadata": {},
   "source": [
    "#### B) Is it good or is it bad?\n",
    "Interpreting our score will be easier if we compare it to a baseline. But what baseline? We face a classification problem. There are two classes, good payers and bad payers, and we aim to tell these apart. Come up with a very basic - naive - strategy to solve the classification problem without using any model. Write a piece of code to calculate the performance of your naive strategy. \n",
    "> Hint: if you feel a bit lost, consider web searching for *naive classifier* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86ca09e4-5475-48f5-b938-10d8d6cd79fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to calculate the score of a naive classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b594ac70-c675-4eae-951a-2210ee923dc8",
   "metadata": {},
   "source": [
    "#### C) What about probabilities?\n",
    "Exactly, what about probabilities? The lecture introduced logistic regression as a machine learning model that predicts class membership probabilities. So the model should answer questions such as \"what is the estimated probability of the first credit applicant in our data set to repay?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f394a7cb-f1d2-4981-b0e0-7c73eb457a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write code to print the prediction of logistic regression for the first data point in our matrix X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8bc848-44a1-4a67-915f-93f335badc9d",
   "metadata": {},
   "source": [
    "Solving the above task, you will find that the prediction does not look like a probability. Examine this point in more detail. To that end, write code that tells you what distinct values logistic regression predict. Briefly explain what these values represent, what is their meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d97a644d-a304-41c2-b07c-3c5177e1ca33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to find out the distinct values of the predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b615d4-5931-42d3-9d64-57db12b4d03e",
   "metadata": {},
   "source": [
    "**What is the meaning of the predictions? Briefly explain.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a016d75f-8cda-47e8-b071-8efca464c6a0",
   "metadata": {},
   "source": [
    "Finally, we come back to the innocent question asked before, \"what is the estimated probability of the first credit applicant in our data set to repay?\". Given our previous analysis has not answered this question it is about time to. Write code to find out the estimated probability of the first applicant to be a bad credit risk. \n",
    "Just in case, mathematically, we could represent the sought probability as $\\hat{p}(BAD=1|X_1)$, put how to get this probability estimate?\n",
    "> Hint: a function to do this is readily available. You could run a web search to locate that function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a8a4de6-29db-4e86-9356-cac4fe339120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to obtain probability predictions from the logit model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8173f614-b287-4e1b-b4a3-2937c88e1383",
   "metadata": {},
   "source": [
    "### Visualizing the logistic regression\n",
    "By now we have an intuition what stronger and weaker features the data set provides and how effective a logistic regression model is to classify repayment behavior when using all the features. \n",
    "\n",
    "#### Exercise 4: One more logistic regression\n",
    "Please estimate a second logistic regression model. This time, use only two features. Exercise 1 has asked you to examine combinations of features. Just continue with the two features you selected there. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e28c593-d90a-43c4-92f6-a2f20364ddc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our first feature is:\t \n",
      "Our second feature is:\t \n"
     ]
    }
   ],
   "source": [
    "print('Our first feature is:\\t', x1)\n",
    "print('Our second feature is:\\t', x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "127568a4-102e-4b5a-9b2b-9a7d522421fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write code to estimate a logistic regression classifier using only the two above features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c727e2-8442-4b32-b857-a747cc36ba62",
   "metadata": {},
   "source": [
    "#### The visual logistic regression\n",
    "As you will have guessed, the point of the above exercise 4 was only to obtain a logistic regression model that we can plot; hence the need to select two features. \n",
    "The visualization is somewhat complex. Thus, all code is readily available for you. Below we provide a function `plot_logit_decision_surface()`. \n",
    "**Do not be put off by the length of the code.** You are not supposed to look through the function at this point. Of course, you are allowed to ;) but do not allow it to confuse you. It is a function to create a plot. That is all you need to know for now. Please execute the cell to make sure you can use the function in the next exercise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a9a3c5d-614f-4ffb-9fd2-f67d66b0ebc2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_logit_decision_surface(model, data, x1, x2, save_fig=False):\n",
    "    '''\n",
    "        Visualization of logistic regression in 2D\n",
    "        \n",
    "        Creates a plot depicting the distribution of the input\n",
    "        data along two dimensions and the probability predictions\n",
    "        of a logistic regression model. \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        model :   An instance of the sklearn class LogisticRegression,  which        \n",
    "                  has been trained on the input data.\n",
    "\n",
    "        data  :   Pandas data frame providing the feature values.\n",
    "\n",
    "        x1, x2:   The function plots the results of logistic regression in\n",
    "                  two dimensions. The parameters x1 and x2 give the names\n",
    "                  of the features used for plotting. These features will be\n",
    "                  extracted from the data frame.\n",
    "\n",
    "        save_fig: Binary variable allowing you to save the figure as a PNG image. \n",
    "                  Default: False\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        The function does not return a result. It's purpose is to visualize \n",
    "        logistic regression model. The corresponding plot is the only output.\n",
    "    '''\n",
    "\n",
    "    #if len(model.coef_.ravel())!=2:\n",
    "    #    raise Exception('Please estimate a logit model using only two features!')\n",
    "    # Define some variables to govern the plot\n",
    "    bounds = data.describe().loc[[\"min\", \"max\"]][[x1, x2]].to_numpy()  # value ranges of the two features\n",
    "    eps = 5  # tolerance parameter \n",
    "\n",
    "    # Create hypothetical data points spanning the entire range of feature values.\n",
    "    # We need these to get from our logistic regression model a probability prediction\n",
    "    # for every possible data point\n",
    "    xx, yy = np.mgrid[(bounds[0,0]-eps):(bounds[1,0]+eps), (bounds[0,1]-eps):(bounds[1,1]+eps)]\n",
    "    grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "\n",
    "    # Perhaps the logistic regression model was fitted using the full data frame. \n",
    "    # To also work in that case, we extract the estimated regression coefficients \n",
    "    # corresponding to the two features we consider for plotting\n",
    "    feature_to_index = {name: idx for idx, name in enumerate(model.feature_names_in_)}  # create a dic as intermediate step\n",
    "    indices = [feature_to_index[f] for f in [x1, x2]]  # Find the indices of our two features of interest using the dic\n",
    "    w = model.coef_.ravel()[indices]  # estimated regression coefficients\n",
    "    b = model.intercept_  # estimated intercept of the logistic regression model\n",
    "\n",
    "    # Compute probability predictions over the entire space of possible feature values\n",
    "    # In the interest of robustness, we manually compute the logistic regression predictions\n",
    "    # using the regression coefficients extracted above\n",
    "    probs = 1/(1+np.exp(-(np.dot(grid, w.reshape(2,-1))+b))).reshape(xx.shape)\n",
    "\n",
    "    # We are finally ready to create our visualization\n",
    "    f, ax = plt.subplots(figsize=(8, 6))  # new figure\n",
    "    # Contour plot of the probability predictions across the entire feature range\n",
    "    contour = ax.contourf(xx, yy, probs, 25, cmap=\"RdBu\", vmin=0, vmax=1)  \n",
    "    ax_c = f.colorbar(contour)\n",
    "    ax_c.set_label(\"$\\hat{p}(y=1|X)$\")\n",
    "    ax_c.set_ticks([0, .25, .5, .75, 1])\n",
    "\n",
    "    # Scatter plot of the actual data\n",
    "    ax.scatter(data[x1], data[x2], c=y, s=50, cmap=\"RdBu\", vmin=0, vmax=1,\n",
    "               edgecolor=\"white\", linewidth=1);\n",
    "    plt.xlabel(x1)\n",
    "    plt.ylabel(x2)\n",
    "    if save_fig==True:\n",
    "        plt.savefig('logit_contour.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0962265-96b0-45d9-8885-34b5ea6e5a95",
   "metadata": {},
   "source": [
    "#### Exercise 5: Contour plot\n",
    "We are almost ready. Also run the next cell, which will give you some instructions on how to use the plotting function. Note that this code also works for other functions. Just put a '?' in front of a function call and run the code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797af5bd-df50-473f-8ece-bb6136ce3dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "?plot_logit_decision_surface"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca16bb2-521e-4a19-b4ea-51aa70d0e180",
   "metadata": {},
   "source": [
    "I guess your next task is obvious. Write code to call the function providing the necessary parameters so that it can do its job. If used correctly, the function will create a plot like this one for the two features you decided to plot:\n",
    "![Contour plot of logistic regression model](https://raw.githubusercontent.com/stefanlessmann/ESMT_IML/main/resources/logit_contour.png)\n",
    "\n",
    "Let's if it works for you..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "48de265c-c77f-47c4-a90d-a5896197f9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write code to call the function plot_logit_decision_surface()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c211ba51-662f-4ced-b428-4dceb0e9d51c",
   "metadata": {},
   "source": [
    "Finally, and hoping you got a nice contour plot of your logistic regression model, it is time to pause and think about the plot. It tells you a lot about how logistic regression works and the output you obtain. This is something we need to discuss in class. \n",
    "\n",
    "# Well done! You made it through another comprehensive set of exercises!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "B0rxPs4QEGtz",
    "27sCENzmoGcX"
   ],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
